#import "../lib.typ": *
#import "../utils.typ": *
#import "@preview/splash:0.3.0": tailwind
#import "@preview/big-todo:0.2.0": *

#pagebreak()

= Fundamental Concepts<fundamental_concepts>
#col[
  == Reverberation Time<reverberation_time> #pmpt

  As introduced in @introduction, reverberation time quantifies the temporal characteristics of sound decay within an enclosed acoustic environment. This parameter serves as a fundamental metric in architectural acoustics, significantly influencing the acoustic behavior and perceptual quality of enclosed spaces @sabineCollectedPapersAcoustics1922. The most prevalent measurement standard is RT60, which defines the time required for sound pressure level to decay by $60$ decibels from its initial value corresponding to one-thousandth of the initial sound pressure level, or equivalently, one-millionth of the initial sound intensity. This measurement exhibits frequency-dependent characteristics, with RT60 values varying substantially across different frequency bands due to the frequency-selective absorption properties of boundary materials @longArchitecturalAcoustics2006. In what follows, the terms _reverberation time_ and _RT60_ are used interchangeably.

  Alternative decay metrics include RT20 and RT30, which measure decay times for $20 "dB"$ and $30 "dB"$ reductions, respectively, with values extrapolated to estimate RT60. These shorter decay measurements are often employed when signal-to-noise ratios are insufficient for reliable $60 "dB"$ decay measurements, with the initial $5 "dB"$ of decay typically ignored to exclude early reflections that may compromise measurement uniformity @ISO3382220082008. RT20 and RT30 values are typically extrapolated to estimate RT60, though this extrapolation may introduce measurement uncertainties in acoustically complex environments.

  === Perceptual Relevance<perceptual_relevance>

  Reverberation time varies significantly depending on a room's purpose, size, geometry, and surface materials. Larger volumes generally yield longer RT60s due to extended sound paths and energy retention. Reflective surfaces increase reverberation, whereas absorptive materials and furnishings — especially with human occupancy — effectively reduce it. Geometric features that scatter sound can modify reflection patterns and decay behavior. Additionally, air absorption, particularly at higher frequencies, and environmental parameters such as humidity further influence RT60, especially in large or acoustically sensitive spaces.

  Literature surveys and established design guidelines in architectural acoustics report typical reverberation time targets for different room types, based on their intended function and acoustic requirements. In general, speech-focused spaces such as classrooms, offices, and conference rooms aim for shorter RT60s — typically between $0.4$ and $0.8$ seconds — to maintain clarity and speech intelligibility. Music rehearsal rooms and small performance spaces may target $0.8$ to $1.2$ seconds, allowing for a balance between clarity and some musical fullness. Large performance venues such as concert halls often aim for RT60s of $1.8$ to $2.2$ seconds, providing a sense of spaciousness, richness, and blend for orchestral music. In contrast, cathedral-like spaces or very large halls can exhibit RT60s exceeding $4$ to $6$ seconds, yielding a highly immersive acoustic character that is favorable for certain musical genres, though typically detrimental to speech intelligibility @doelleEnvironmentalAcoustics1972.

  Recent research highlights that even small variations in reverberation time can have a measurable impact on listener perception and cognitive load. For instance, a controlled increase of just $0.12" s"$ — from $0.57" s"$ to $0.69" s"$ — was found to significantly affect children's listening effort and performance in typical classroom tasks @prodiSlightIncreaseReverberation2022. This underscores the perceptual sensitivity to reverberation, particularly in speech-critical environments. The just noticeable difference (JND) for RT60 is specified in ISO 3382-1 as approximately $5%$, yet empirical studies suggest it may be substantially higher: #cite(<pengQuantifyingJustNoticeable>, form: "prose") and #cite(<delsolardorregoStudyJustNoticeable2022>, form: "prose") report values ranging from 18% to 25%, depending on the acoustic context and task. These findings reinforce the importance of accurate and context-aware RT60 estimation — especially for immersive audio applications such as augmented reality, where mismatches between perceived and actual room acoustics (i.e., the room divergence effect) can reduce plausibility and user comfort.

  === Measurement and Estimation

  RT60 can be determined through direct measurement, computational simulation, or predictive calculation methodologies, with machine learning approaches increasingly being employed for complex acoustic modeling.

  ==== Theoretical Calculation Methods

  Direct measurement of RT60 requires considerable instrumentation and temporal resources, whereas theoretical calculation demands minimal equipment but extensive parameter determination @beranekConcertHallsOpera2010. Calculation-based approaches necessitate manual acquisition of room-specific variables, including volumetric dimensions, boundary surface areas, and absorption coefficients of constituent materials. Multiple theoretical frameworks exist for RT60 estimation, including the Sabine, Norris-Eyring, and Millington-Sette equations @longArchitecturalAcoustics2006. These formulations demonstrate that reverberation time increases proportionally with room volume and inversely with total acoustic absorption.

  Research indicates that the Sabine equation provides the most accurate RT60 estimation among commonly employed theoretical methods @kuttruffRoomAcoustics2006. Due to its minimal parametric requirements, the Sabine approach also offers superior computational efficiency for practical RT60 calculation.

  *Sabine Formula* @sabineReverberation1922:
  $
    "RT"_60 approx 0.161 (V/sum(alpha_i A_i))
  $
  where:
  - $V$ = Volume of the room ($"m"^3$)
  - $A_i$ = Surface area of each boundary ($"m"^2$)
  - $alpha_i$ = Absorption coefficient of each boundary

  The Sabine formula assumes uniform sound energy distribution throughout the acoustic volume and is typically applied to spaces with varying absorption characteristics @cremerPrinciplesApplicationsRoom1982. It is crucial to recognize that this formulation provides an estimation rather than an exact calculation, as it does not account for all physical phenomena influencing sound decay, including diffraction effects, coupled volumes, and non-uniform absorption distributions @kuttruffRoomAcoustics2006.

  ==== Manual Measurement<rev_man_meas>
  Manual measurement of reverberation time (RT60) follows standardized procedures outlined in ISO 3382-1:2009 @ISO338212009, which specifies two primary methods: the interrupted noise method and the integrated impulse response method. The interrupted noise method involves energizing a room with broadband or band-limited noise from an omnidirectional source, then abruptly terminating the signal and measuring the subsequent decay of sound pressure levels across frequency bands @RT60ReverberationTime. Alternatively, the impulse response method utilizes impulsive sound sources such as balloon pops or starter pistols to excite the room, followed by analysis of the decay characteristics from the recorded impulse response @ReverberationTimeRoom. Both methods require evaluation of decay curves starting 5 dB below the initial sound pressure level, with RT60 values commonly extrapolated from smaller dynamic ranges (RT20 or RT30) when the full 60 dB decay cannot be achieved due to background noise limitations.

  A typical measurement setup is constructed as shown in @measurement_sketch, where the microphone must be positioned outside the critical distance from the sound source to ensure measurements are taken within the diffuse sound field rather than the direct sound field. This placement is crucial for obtaining accurate reverberation time measurements that represent the room's overall acoustic character. The measurement process must also account for spatial averaging across multiple source and receiver positions to ensure representative results, with specific positioning requirements and measurement uncertainties detailed in the standard.

  Contemporary RT60 measurements increasingly utilize sine sweep methods and sophisticated analytical approaches for enhanced accuracy and noise rejection. Exponential Sine Sweep (ESS) techniques have gained prominence alongside Maximum Length Sequences (MLS) as test signals for acquiring impulse responses, offering superior signal-to-noise ratios and immunity to time-variant distortions compared to traditional methods @SimultaneousMeasurementImpulse. The Lundeby method @lundebyUncertaintiesMeasurementsRoom1995 represents a significant advancement in decay curve analysis, providing an objective algorithm for determining the noise floor and optimizing the evaluation range for RT60 calculations by identifying the intersection point between the decay curve and background noise level. This fitting process accounts for exponential decay plus noise functions and addresses the effect of windowing on measurement accuracy, particularly crucial when measuring in acoustically challenging environments where the full 60 dB dynamic range cannot be achieved. These analytical methods enable more robust RT60 determination by automatically selecting appropriate evaluation ranges and providing statistical confidence measures for the resulting reverberation time values.

  #figure(
    image("../images/audio-installation-to-evaluate-reverberation-properties.png"),
    caption: [Sketch of a setup for measuring reverberation times @MethodsReverbTime],
  )<measurement_sketch>

  ==== Simulation Methods
  Simulation methods for estimating RT60 utilize computational models to predict acoustic behavior within enclosed spaces, eliminating the need for physical measurements while accounting for room geometry and material properties @kuttruffRoomAcoustics2006. These approaches range from geometric approximations to full wave-equation solutions, each offering different trade-offs between computational efficiency and physical accuracy @vorlanderAuralizationFundamentalsAcoustics2008.

  The Image Source Method represents a geometric approach that models reflections as virtual sources mirrored across room boundaries, effectively capturing early reflections through straight-line path tracing @allenImageMethodEfficiently1979. This method proves computationally efficient for simple rectangular geometries, though its complexity increases exponentially with reflection order @borishExtensionImageModel1984. Ray tracing methods complement the image source approach by emitting numerous rays from the source and tracking their interactions with surfaces, excelling at modeling late, dense reflections in complex geometries where clean mirror paths become insufficient @krokstadCalculatingAcousticalRoom1968 @vorlanderAuralizationFundamentalsAcoustics2008. While flexible and capable of integrating statistical diffusion models, ray tracing typically neglects diffraction and wave effects that become significant at lower frequencies @saviojaOverviewGeometricalRoom2015.

  Wave-based methods provide the highest physical accuracy by solving the complete wave equation, capturing phenomena such as diffraction, interference, and low-frequency modal behaviors that geometric methods cannot represent @hamiltonTutorialFinitedifferenceTimedomain2021 @marburgComputationalAcousticsNoise2008. These approaches employ techniques including Finite Difference Time Domain (FDTD), Boundary Element Methods (BEM), and Discontinuous Galerkin (DG) solvers to achieve comprehensive acoustic modeling @bilbaoNumericalSoundSynthesis2009 @thompsonReviewFiniteelementMethods2006. However, their computational intensity limits practical application to smaller volumes or coarser spatial resolutions. To address these limitations, hybrid methods have emerged that combine wave solvers for low-frequency accuracy with geometric simulations for high-frequency efficiency @wittebolHybridRoomAcoustic2024.

  For our synthetic data generation, we employed multiple simulation approaches to balance computational efficiency with acoustic accuracy. The Image Source Method was implemented through both the Treble SDK's @Treble ISM mode and pyroomacoustics  @scheiblerPyroomacousticsPythonPackage2018 for rapid processing of large datasets. When higher fidelity was required, we utilized Treble's hybrid and wave-based modes, which provide more accurate low-frequency modeling at the cost of increased computational resources. This multi-modal simulation approach enabled us to generate diverse acoustic datasets while maintaining reasonable processing times.

  == Artificial Intelligence and Deep Learning #bv
  Artificial Intelligence (AI) represents a transformative computational paradigm that enables machines to perform tasks traditionally requiring human cognitive abilities, with its conceptual origins tracing back to the 1950s @kaplanArtificialIntelligenceWhat2016. Contemporary AI systems, more precisely categorized as Artificial Narrow Intelligence (ANI), demonstrate specialized competencies within defined domains rather than the broad, generalized intelligence characteristic of human cognition @witmayerAutomatingMetadataLogging2018. The field has witnessed remarkable advancement through various methodological approaches, including image recognition @ashqarImageBasedTomatoLeaves2019, speech processing @alhawitiAdvancesArtificialIntelligence2015, and pattern classification @nanniCombiningVisualAcoustic2016, though applications within acoustics and audio processing remain relatively underexplored. Deep Learning (DL) emerges as a particularly influential subset of AI, employing multi-layered artificial neural networks that process hierarchical data representations to extract meaningful patterns and generate predictive outputs @kapoorDeepLearningTensorFlow2019. The fundamental DL methodology involves training these networks on substantial datasets comprising features (input data) and corresponding labels (desired outputs), enabling the system to learn complex mappings between input patterns and target classifications through iterative mathematical optimization @ashqarImageBasedTomatoLeaves2019@kapoorDeepLearningTensorFlow2019. However, this approach presents significant challenges, particularly the requirement for extensive, high-quality training datasets, which can be both time-intensive to acquire and difficult to obtain in specialized domains such as acoustic analysis. Despite these limitations, deep learning architectures have demonstrated exceptional performance in various computer vision tasks, establishing them as powerful tools for applications requiring sophisticated pattern recognition capabilities.

  == Convolutional Neural Networks #bv
  Convolutional Neural Networks (CNN's) represent a specialized class of deep learning neural networks particularly well-suited for processing grid-like data structures such as images. The fundamental architecture of CNN's leverages three key principles: local connectivity, parameter sharing, and translation equivariance, which make them highly effective for computer vision tasks such as our reverberation time estimation from images. Unlike traditional fully connected networks, CNN's employ convolutional layers that apply learnable filters across input data, enabling the network to detect local features such as edges, textures and spatial patterns while maintaining computational efficiency @geronHandsonMachineLearning2023.

  The typical CNN architecture consists of alternating convolutional and pooling layers followed by fully connected layers for classification or regression tasks. Convolutional layers perform feature extraction through the application of multiple filters, each learning to detect specific patterns in the input data. Pooling layers (commonly max pooling or average pooling) reduce the spatial dimensions while preserving important features, contributing to the network's robustness to small translations and reducing computational overhead. This hierarchical feature learning allows CNN's to capture both low-level features (e.g., edges, corners) in early layers and increasingly higher-level semantic information (e.g., object parts, textures) in deeper layers @geronHandsonMachineLearning2023.

  === Transfer Learning and Pre-trained Models
  Transfer learning has emerged as a crucial technique in modern deep learning, particularly when dealing with limited training data or computational resources. The core principle involves leveraging knowledge gained from training on large-scale datasets and applying it to related target tasks @geronHandsonMachineLearning2023.

  Pre-trained models, such as ResNet @heDeepResidualLearning2015 architectures trained on ImageNet @dengImageNetLargescaleHierarchical2009 or specialized datasets like Places365 @zhouPlaces10Million2018, provide robust feature representations that capture fundamental visual patters. Places365-trained models are particularly relevant for architectural and spatial understanding tasks, as they have been trained on scene recognition data that includes various indoor and outdoor environments. This makes them well-suited as backbone networks for applications involving room analysis or spatial acoustic modelling, where understanding environmental context is crucial.

  The implementation of transfer learning for CNN's can follow different strategies: feature extraction, where pre-trained layers are frozen and used as fixed feature extractors, or fine-tuning, where the entire network or selected layers are updated with a lower learning rate. The choice between these approaches depends on the similarity between source and target domains, the amount of available training data and computational constraints.

  === Loss Functions for Regression
  In regression tasks, the choice of loss function significantly impacts model performance and training dynamics. Mean Squared Error (MSE) remains the most commonly used loss function for regression problems due to its mathematical properties and ease of optimization, computing the average squared difference between predicted and target values @goodfellowDeepLearning2016 @MeanSquaredError2025.
  For multi-dimensional regression outputs, such as predicting reverberation times across multiple frequency bands, individual frequency band losses can be monitored separately while the overall loss represents the aggregate error across all dimensions. The selection of appropriate optimizers like AdamW @kingmaAdamMethodStochastic2017 @loshchilovDecoupledWeightDecay2019, which incorporates weight decay regularization @geronHandsonMachineLearning2023, and learning rate scheduling techniques such as ReduceLROnPlateau @ReduceLROnPlateauPyTorch27 help achieve better convergence and avoid overfitting @geronHandsonMachineLearning2023.
]
